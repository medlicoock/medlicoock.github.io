<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>MEDLI Project</title>
    <style>
        body {
            margin: 0;
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, sans-serif;
            line-height: 1.6;
            color: white;
        }

        .background {
            min-height: 100vh;
            background-image: url('MEDLI.png');
            background-size: cover;
            background-position: center;
            background-repeat: no-repeat;
        }

        .overlay {
            min-height: 100vh;
            background-color: rgba(0, 0, 0, 0.5);
            padding: 2rem;
        }

        .container {
            max-width: 800px;
            margin: 0 auto;
        }

        h2 {
            font-size: 2rem;
            margin-top: 2rem;
            color: #fff;
        }

        ul {
            margin-left: 1.5rem;
        }

        a {
            color: #7dd3fc;
            text-decoration: none;
        }

        a:hover {
            text-decoration: underline;
        }

        .section {
            margin-bottom: 2rem;
        }
    </style>
</head>
<body>
    <div class="background">
        <div class="overlay">
            <div class="container">
                <div class="section">
                    <h2>CHALLENGE</h2>
                    <p>An increasing number of companies see the potential of AI at the 'edge' of the network, i.e., performing local data processing to enable real-time decisions without relying on the cloud. At the same time, modern deep-learning models are growing larger at a rapid pace, making it challenging to deploy them on edge devices with limited computing power and memory.</p>
                    <p>On top of that, companies often struggle with:</p>
                    <ul>
                        <li>Specializing (transfer learning) and sufficiently "compressing" large pre-trained AI models so they can run both quickly and accurately on edge platforms.</li>
                        <li>Choosing the best combination of edge hardware and software for their specific needs.</li>
                        <li>Monitoring deployed AI models in operation, so they can quickly detect and address declines in performance or accuracy.</li>
                    </ul>
                </div>

                <div class="section">
                    <h2>PROJECT GOALS</h2>
                    <p>Within the <strong>MEDLI</strong> project (<strong>M</strong>aking <strong>E</strong>dge <strong>AI</strong> <strong>D</strong>eployment <strong>L</strong>ight and <strong>I</strong>mpactful), we tackle these challenges and provide practical, industry-ready solutions. We consolidate state-of-the-art knowledge into a user-friendly approach that allows companies to:</p>
                    
                    <h3>1. Accelerate edge AI model development</h3>
                    <ul>
                        <li>Leverage pre-trained deep learning models and transfer-learning techniques.</li>
                        <li>Compress these models (e.g., pruning, quantization) to reduce their size while maintaining sufficient accuracy.</li>
                    </ul>

                    <h3>2. Easily select the right hardware and software</h3>
                    <ul>
                        <li>An overview of relevant edge hardware (GPU, TPU, CPU, etc.) and corresponding compilers & deployment tools.</li>
                        <li>Practical guidelines and decision trees: which solution best fits your application requirements?</li>
                    </ul>

                    <h3>3. Monitor AI models in operation</h3>
                    <ul>
                        <li>Best practices and tool overviews to keep tabs on a model's health (accuracy, errors, drift).</li>
                        <li>Automatic detection of performance drops, with triggers for re-training or other adjustments.</li>
                    </ul>

                    <h3>4. Generic use cases and demonstrations</h3>
                    <ul>
                        <li>A sample use case on image processing (e.g. vision systems for quality inspection).</li>
                        <li>A sample use case on time-series data (e.g. vibration, sensor, or audio signals).</li>
                        <li>Both are fully worked out with step-by-step documentation, serving as a blueprint for companies.</li>
                    </ul>
                </div>

                <div class="section">
                    <h2>HOW DOES IT WORK?</h2>
                    <ul>
                        <li>We collect and translate existing research outcomes on model compression, edge-hardware prototyping, and AI monitoring.</li>
                        <li>We develop an intuitive graphical interface that lets you adapt and optimize pre-trained models using your own (limited) dataset.</li>
                        <li>We provide guides, workshops, and webinars to get your R&D team up to speed.</li>
                        <li>We offer follow-up activities for companies interested in taking the MEDLI approach further in their own applications.</li>
                    </ul>
                </div>

                <div class="section">
                    <h2>RESULTS</h2>
                    <p>Companies joining or following MEDLI can:</p>
                    <ul>
                        <li><strong>Save time and effort</strong>: shorten the design cycle for edge AI models by up to 80%.</li>
                        <li><strong>Make informed choices</strong>: rely on decision trees to pick the right hardware, compiler, and deployment approach.</li>
                        <li><strong>Stay in control</strong>: easily monitor the performance of on-device AI and make timely adjustments.</li>
                    </ul>
                </div>

                <div class="section">
                    <h2>FOR WHOM?</h2>
                    <ul>
                        <li>Industrial end-users (manufacturing, automotive, agriculture, energy, â€¦) wanting real-time local data processing.</li>
                        <li>Technology and software providers delivering AI solutions and looking to support edge-based deployments for their clients.</li>
                        <li>System integrators building smart devices or production lines with on-site AI capabilities.</li>
                    </ul>
                </div>

                <div class="section">
                    <h2>PARTNERS</h2>
                    <p>This project is an initiative by <strong>KULeuven</strong> and <strong>Flanders Make</strong>, in close collaboration with various industry partners. Through VLAIO's COOCK program, we aim to bridge the gap between academic expertise and real-world industrial applications.</p>
                </div>

                <div class="section">
                    <h2>CONTACT</h2>
                    <p>Interested in how MEDLI can boost your edge AI deployment or want to join the user group? Get in touch:</p>
                    <p><strong>Marjolein Deryck, project manager</strong><br>
                    Email: <a href="mailto:marjolein.deryck@kuleuven.be">marjolein.deryck@kuleuven.be</a></p>
                </div>
            </div>
        </div>
    </div>
</body>
</html>